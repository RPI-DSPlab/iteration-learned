{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Visualisation of the Prediction Depth of CIFAR-10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Read output from `get_pd`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-04T15:50:37.761421570Z",
     "start_time": "2023-07-04T15:50:37.720016162Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 28\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m json_files, il_dict_list\n\u001B[1;32m     27\u001B[0m _, il_dict \u001B[38;5;241m=\u001B[39m read_il_files(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(os\u001B[38;5;241m.\u001B[39mgetcwd(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mil_results\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavg\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m---> 28\u001B[0m il_dict \u001B[38;5;241m=\u001B[39m \u001B[43mil_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_il_files(directory: str) -> tuple[list[str], list[dict]]:\n",
    "    \"\"\"\n",
    "    This function is going to read all .pkl file from a give directory\n",
    "    @param directory: ..\n",
    "    @return: ([file name list], [dict list])\n",
    "    \"\"\"\n",
    "    il_dict_list = []\n",
    "    file_list = os.listdir(directory)\n",
    "    json_files = [file for file in file_list if file.endswith(\"train_epoch.json\")]\n",
    "\n",
    "    for json_file in json_files:\n",
    "        file_path = os.path.join(directory, json_file)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            dict_load = json.load(f)\n",
    "            int_key_dict = {}\n",
    "            for key, value in dict_load.items():\n",
    "                int_key_dict[int(key)] = value\n",
    "            il_dict_list.append(int_key_dict)\n",
    "\n",
    "\n",
    "    return json_files, il_dict_list\n",
    "\n",
    "\n",
    "_, il_dict = read_il_files(os.path.join(os.getcwd(), \"il_results\", \"avg\"))\n",
    "il_dict = il_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Link `il_dict` to `cifar10` dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import PILToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CIFAR10PD(CIFAR10):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        super(CIFAR10PD, self).__init__(root, train, transform, target_transform, download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # to get (img, target), index\n",
    "        img, target = super(CIFAR10PD, self).__getitem__(index)\n",
    "        return PILToTensor()(img), target, index\n",
    "trainset = CIFAR10PD('./', train=False, download=True)\n",
    "testset = CIFAR10PD('./', train=True, download=True)\n",
    "\n",
    "dataloader_train = DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "dataloader_test = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "CIFAR_dict = {}\n",
    "\n",
    "for imgs, targets, indexes in dataloader_train:\n",
    "    for img, target, index in zip(imgs, targets, indexes):\n",
    "        CIFAR_dict[index.item()] = (img, target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_np = CIFAR_dict[1198][0].numpy()\n",
    "image_np = image_np.transpose(1, 2, 0)\n",
    "\n",
    "# Plot the CIFAR-10 image\n",
    "plt.imshow(image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - split the unlearned images and learned images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learned_il_dict = {}\n",
    "unlearned_il_dict = {}\n",
    "\n",
    "for index, score in il_dict.items():\n",
    "    if score == -1:\n",
    "        unlearned_il_dict[index] = -1\n",
    "    else:\n",
    "        learned_il_dict[index] = score\n",
    "\n",
    "def imgHardnessLink(img_dict: dict, hardness_dict:dict) -> dict:\n",
    "    \"\"\"\n",
    "    This function gives each image its hardness score\n",
    "    @param img_dict: dictionary of image in the format of {index : (img, target)}\n",
    "    @param pd_dict: dictionary of image in the format of {index : PD score}\n",
    "    @return: dictionary of {img : (target, PD score)}\n",
    "    \"\"\"\n",
    "\n",
    "    img_hardness_dict = {}\n",
    "    for index in (set(hardness_dict.keys()).intersection(set(img_dict.keys()))):\n",
    "        img_hardness_dict[img_dict[index][0]] = (img_dict[index][1], hardness_dict[index], index)\n",
    "    return img_hardness_dict\n",
    "\n",
    "\n",
    "learned_img_IL_dict = imgHardnessLink(CIFAR_dict, learned_il_dict)\n",
    "unlearned_il_dict = imgHardnessLink(CIFAR_dict, unlearned_il_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### -Visualisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation of the iteration learned of CIFAR-10, we grab 10 images for each score after scaled\n",
    "scaled_img_IL_dict = {}\n",
    "for key, (img, score, index) in learned_img_IL_dict.items():\n",
    "    scaled_img_IL_dict[key] = (img, round(score/10), index)\n",
    "max_score = max([score for (_, score, _) in scaled_img_IL_dict.values()])\n",
    "min_score = min([score for (_, score, _) in scaled_img_IL_dict.values()])\n",
    "images_per_score = [[] for _ in range(max_score + 1)]\n",
    "for img, (target, score, index) in scaled_img_IL_dict.items():\n",
    "    images_per_score[score].append((img, target, index)) if len(images_per_score[score]) < 10 else None\n",
    "\n",
    "target_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for score, images in enumerate(images_per_score):\n",
    "    if len(images) == 0:\n",
    "        continue\n",
    "    print(f\"Score: {score+1}\")\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(20, 20))\n",
    "    for i, (img, target, index) in enumerate(images):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(target_names[target])\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting 10 never learned images in unlearned_il_dict\n",
    "ten_unlearned_images = list(unlearned_il_dict.items())[:10]\n",
    "fig, axes = plt.subplots(1, len(ten_unlearned_images), figsize=(20, 20))\n",
    "for i, (img, (target, score, index)) in enumerate(ten_unlearned_images):\n",
    "    img = img.numpy()\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(target_names[target])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare Iteration Learned with Prediction Depth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_pd_files(directory: str) -> tuple[list[str], list[dict]]:\n",
    "    \"\"\"\n",
    "    This function is going to read all .pkl file from a give directory\n",
    "    @param directory: ..\n",
    "    @return: ([file name list], [dict list])\n",
    "    \"\"\"\n",
    "    pd_dict_list = []\n",
    "    file_list = os.listdir(directory)\n",
    "    pkl_files = [file for file in file_list if file.endswith(\".pkl\")]\n",
    "\n",
    "    for pkl_file in pkl_files:\n",
    "        file_path = os.path.join(directory, pkl_file)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            dict_load = json.load(f)\n",
    "\n",
    "            for i in dict_load.keys():\n",
    "                dict_load[i] = dict_load[i][0] # list of 1 int -> int\n",
    "\n",
    "            pd_dict_list.append(dict_load)\n",
    "\n",
    "    return pkl_files, pd_dict_list\n",
    "\n",
    "\n",
    "pd_result_dir = os.path.join(os.getcwd(), \"cl_results_single\") # change the second argument to specify the result file\n",
    "file_name_list, pd_dicts = read_pd_files(pd_result_dir)\n",
    "number_of_pd_result = len(pd_dicts)\n",
    "pd_avg_dict = {}\n",
    "\n",
    "# calculate the average of all pd_dict\n",
    "for pd_dict in pd_dicts:\n",
    "    for i in pd_dict.keys():\n",
    "        pd_avg_dict[int(i)] = pd_avg_dict.get(int(i)) + pd_dict[i] if (int(i) in pd_avg_dict.keys()) else pd_dict[i]\n",
    "for i in pd_avg_dict:\n",
    "    pd_avg_dict[i] = round((pd_avg_dict[i])/number_of_pd_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "imgPD_dict = imgHardnessLink(CIFAR_dict, pd_avg_dict)\n",
    "imgIL_dict = imgHardnessLink(CIFAR_dict, il_dict)\n",
    "\n",
    "# relabel all -1 (unlearned) example to 10\n",
    "il_dict_all = {}\n",
    "for key, (img, score, index) in imgIL_dict.items():\n",
    "    if score == -1:\n",
    "        il_dict_all[key] = (img, 10, index)\n",
    "    else:\n",
    "        il_dict_all[key] = (img, round(score/10), index) # divide 10 because we know the max score is 80\n",
    "\n",
    "common_keys = set(imgPD_dict.keys()).intersection(il_dict_all.keys())\n",
    "\n",
    "score_il = []\n",
    "score_pd = []\n",
    "for key in common_keys:\n",
    "    score_il.append(il_dict_all[key][1])\n",
    "    score_pd.append(imgPD_dict[key][1])\n",
    "\n",
    "sns.regplot(x=score_il, y=score_pd, scatter_kws={\"color\": \"blue\", \"alpha\": 0.3}, line_kws={\"color\": \"red\"})\n",
    "plt.xlabel(\"Iteration Learned\")\n",
    "plt.ylabel(\"Prediction Depth\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
