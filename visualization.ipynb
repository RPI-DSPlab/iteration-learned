{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Visualisation of the Prediction Depth of CIFAR-10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Read output from `get_pd`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_avg_files(directory: str, train=True):\n",
    "    \"\"\"\n",
    "    This function reads the avg.json file from the directory\n",
    "    :param directory:\n",
    "    :param train: True if we wants train_avg.json, False if we wants test_avg.json\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    file_list = os.listdir(directory)\n",
    "    if train:\n",
    "        json_files = [file for file in file_list if file.endswith(\"train_avg.json\")]\n",
    "    else:\n",
    "        json_files = [file for file in file_list if file.endswith(\"test_avg.json\")]\n",
    "\n",
    "    if len(json_files) == 0:\n",
    "        raise FileNotFoundError(\"No {}avg.json file found in the directory\".format(\"train\" if train else \"test\"))\n",
    "    elif len(json_files) > 1:\n",
    "        raise FileExistsError(\"More than one {}avg.json file found in the directory\".format(\"train\" if train else \"test\"))\n",
    "    else:\n",
    "        with open(os.path.join(directory, json_files[0]), \"r\") as f:\n",
    "            avg_dict = json.load(f)\n",
    "\n",
    "    return avg_dict\n",
    "\n",
    "\n",
    "il_dict_train = read_avg_files(os.path.join(os.getcwd(), \"il_results\", \"avg\"), train=True)\n",
    "il_dict_test = read_avg_files(os.path.join(os.getcwd(), \"il_results\", \"avg\"), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T22:26:03.849810946Z",
     "start_time": "2023-07-13T22:26:03.832178884Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Link `il_dict` to `cifar10` dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import PILToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CIFAR10PD(CIFAR10):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        super(CIFAR10PD, self).__init__(root, train, transform, target_transform, download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # to get (img, target), index\n",
    "        img, target = super(CIFAR10PD, self).__getitem__(index)\n",
    "        return PILToTensor()(img), target, index\n",
    "trainset = CIFAR10PD('./', train=False, download=True)\n",
    "testset = CIFAR10PD('./', train=True, download=True)\n",
    "\n",
    "dataloader_train = DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "dataloader_test = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "CIFAR_dict_train = {}\n",
    "CIFAR_dict_test = {}\n",
    "\n",
    "for imgs, targets, indexes in dataloader_train:\n",
    "    for img, target, index in zip(imgs, targets, indexes):\n",
    "        CIFAR_dict_train[index.item()] = (img, target)\n",
    "\n",
    "for imgs, targets, indexes in dataloader_test:\n",
    "    for img, target, index in zip(imgs, targets, indexes):\n",
    "        CIFAR_dict_test[index.item()] = (img, target)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-13T22:26:03.839121971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_np = CIFAR_dict_train[1198][0].numpy()\n",
    "image_np = image_np.transpose(1, 2, 0)\n",
    "\n",
    "# Plot the CIFAR-10 image\n",
    "plt.imshow(image_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - split the unlearned images and learned images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learned_il_dict_train = {}\n",
    "unlearned_il_dict_train = {}\n",
    "learned_il_dict_test = {}\n",
    "unlearned_il_dict_test = {}\n",
    "\n",
    "for index, score in il_dict_train.items():\n",
    "    if score == -1:\n",
    "        learned_il_dict_train[index] = -1\n",
    "    else:\n",
    "        learned_il_dict_train[index] = score\n",
    "\n",
    "for index, score in il_dict_test.items():\n",
    "    if score == -1:\n",
    "        learned_il_dict_test[index] = -1\n",
    "    else:\n",
    "        learned_il_dict_test[index] = score\n",
    "\n",
    "def imgHardnessLink(img_dict: dict, hardness_dict:dict) -> dict:\n",
    "    \"\"\"\n",
    "    This function gives each image its hardness score\n",
    "    @param img_dict: dictionary of image in the format of {index : (img, target)}\n",
    "    @param pd_dict: dictionary of image in the format of {index : PD score}\n",
    "    @return: dictionary of {img : (target, PD score)}\n",
    "    \"\"\"\n",
    "\n",
    "    # type checking to make sure the key is int\n",
    "    type_check = [type(k) for k in img_dict.keys()]\n",
    "    if not all([t == int for t in type_check]):\n",
    "        new_dict = {}\n",
    "        for k, v in img_dict.items():\n",
    "            new_dict[int(k)] = v\n",
    "        img_dict = new_dict\n",
    "\n",
    "    type_check = [type(k) for k in hardness_dict.keys()]\n",
    "    if not all([t == int for t in type_check]):\n",
    "        new_dict = {}\n",
    "        for k, v in hardness_dict.items():\n",
    "            new_dict[int(k)] = v\n",
    "        hardness_dict = new_dict\n",
    "\n",
    "    img_hardness_dict = {}\n",
    "    for index in (set(hardness_dict.keys()).intersection(set(img_dict.keys()))):\n",
    "        img_hardness_dict[img_dict[index][0]] = (img_dict[index][1], hardness_dict[index], index)\n",
    "    return img_hardness_dict\n",
    "\n",
    "\n",
    "learned_img_IL_dict_train = imgHardnessLink(CIFAR_dict_train, learned_il_dict_train)\n",
    "unlearned_il_dict_train = imgHardnessLink(CIFAR_dict_train, unlearned_il_dict_train)\n",
    "learned_img_IL_dict_test = imgHardnessLink(CIFAR_dict_test, learned_il_dict_test)\n",
    "unlearned_il_dict_test = imgHardnessLink(CIFAR_dict_test, unlearned_il_dict_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### -Visualisation (trainset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation of the iteration learned of CIFAR-10, we grab 10 images for each score after scaled\n",
    "scaled_img_IL_dict_train = {}\n",
    "for key, (img, score, index) in learned_img_IL_dict_train.items():\n",
    "    scaled_img_IL_dict_train[key] = (img, round(score/20), index)\n",
    "max_score = max([score for (_, score, _) in scaled_img_IL_dict_train.values()])\n",
    "min_score = min([score for (_, score, _) in scaled_img_IL_dict_train.values()])\n",
    "images_per_score = [[] for _ in range(max_score + 1)]\n",
    "for img, (target, score, index) in scaled_img_IL_dict_train.items():\n",
    "    images_per_score[score].append((img, target, index)) if len(images_per_score[score]) < 10 else None\n",
    "\n",
    "target_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for score, images in enumerate(images_per_score):\n",
    "    if len(images) == 0:\n",
    "        continue\n",
    "    print(f\"Score: {score+1}\")\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(20, 20))\n",
    "    for i, (img, target, index) in enumerate(images):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(target_names[target])\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting 10 never learned images in unlearned_il_dict\n",
    "if len(unlearned_il_dict_train) < 10:\n",
    "    print(\"There are less than 10 unlearned images\")\n",
    "else:\n",
    "    ten_unlearned_images = list(unlearned_il_dict_train.items())[:10]\n",
    "    fig, axes = plt.subplots(1, len(ten_unlearned_images), figsize=(20, 20))\n",
    "    for i, (img, (target, score, index)) in enumerate(ten_unlearned_images):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(target_names[target])\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare Iteration Learned with Prediction Depth (train set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pd_avg_dict_train = read_avg_files('./pd_results/avg', train=True)\n",
    "\n",
    "imgPD_dict = imgHardnessLink(CIFAR_dict_train, pd_avg_dict_train)\n",
    "imgIL_dict = imgHardnessLink(CIFAR_dict_train, il_dict_train)\n",
    "\n",
    "# relabel all -1 (unlearned) example to 10\n",
    "il_dict_all = {}\n",
    "for key, (img, score, index) in imgIL_dict.items():\n",
    "    if score == -1:\n",
    "        il_dict_all[key] = (img, 10, index)\n",
    "    else:\n",
    "        il_dict_all[key] = (img, score, index)\n",
    "\n",
    "common_keys = set(imgPD_dict.keys()).intersection(il_dict_all.keys())\n",
    "\n",
    "score_il = []\n",
    "score_pd = []\n",
    "for key in common_keys:\n",
    "    score_il.append(il_dict_all[key][1])\n",
    "    score_pd.append(imgPD_dict[key][1])\n",
    "\n",
    "sns.regplot(x=score_il, y=score_pd, scatter_kws={\"color\": \"blue\", \"alpha\": 0.3}, line_kws={\"color\": \"red\"})\n",
    "plt.xlabel(\"Iteration Learned\")\n",
    "plt.ylabel(\"Prediction Depth\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare Iteration Learned with Prediction Depth (test set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd_avg_dict_test = read_avg_files('./pd_results/avg', train=False)\n",
    "#\n",
    "# imgPD_dict = imgHardnessLink(CIFAR_dict_test, pd_avg_dict_test)\n",
    "# imgIL_dict = imgHardnessLink(CIFAR_dict_test, il_dict_test)\n",
    "#\n",
    "# # relabel all -1 (unlearned) example to 10\n",
    "# il_dict_all = {}\n",
    "# for key, (img, score, index) in imgIL_dict.items():\n",
    "#     if score == -1:\n",
    "#         il_dict_all[key] = (img, 10, index)\n",
    "#     else:\n",
    "#         il_dict_all[key] = (img, round(score/10), index) # divide 20 because we know the max score is 80\n",
    "#\n",
    "# common_keys = set(imgPD_dict.keys()).intersection(il_dict_all.keys())\n",
    "#\n",
    "# score_il = []\n",
    "# score_pd = []\n",
    "# for key in common_keys:\n",
    "#     score_il.append(il_dict_all[key][1])\n",
    "#     score_pd.append(imgPD_dict[key][1])\n",
    "#\n",
    "# sns.regplot(x=score_il, y=score_pd, scatter_kws={\"color\": \"blue\", \"alpha\": 0.3}, line_kws={\"color\": \"red\"})\n",
    "# plt.xlabel(\"Iteration Learned\")\n",
    "# plt.ylabel(\"Prediction Depth\")\n",
    "# plt.grid(True, linestyle='--', alpha=0.5)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare Pearson's Correlation Coefficient (train set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Creating lists of scores from il_dict_all and imgPD_dict for common keys\n",
    "score_il = []\n",
    "score_pd = []\n",
    "for key in common_keys:\n",
    "    score_il.append(il_dict_all[key][1])\n",
    "    score_pd.append(imgPD_dict[key][1])\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape the scores to be 2D arrays\n",
    "score_il_2d = np.array(score_il).reshape(-1, 1)\n",
    "score_pd_2d = np.array(score_pd).reshape(-1, 1)\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "score_il_scaled = scaler.fit_transform(score_il_2d)\n",
    "score_pd_scaled = scaler.fit_transform(score_pd_2d)\n",
    "\n",
    "# Calculating the Pearson's correlation coefficient and p-value using normalized scores\n",
    "correlation, p_value = pearsonr(score_il_scaled, score_pd_scaled)\n",
    "\n",
    "# Plotting the scatter plot\n",
    "sns.regplot(x=score_il_scaled, y=score_pd_scaled, scatter_kws={\"color\": \"blue\", \"alpha\": 0.3}, line_kws={\"color\": \"red\"})\n",
    "\n",
    "# Adding labels and grid to the plot\n",
    "plt.xlabel(\"Iteration Learned\")\n",
    "plt.ylabel(\"Prediction Depth\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n",
    "\n",
    "# Printing the correlation coefficient and p-value\n",
    "print(\"Pearson's correlation coefficient:\", correlation)\n",
    "print(\"p-value:\", p_value)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
